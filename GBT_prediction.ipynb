{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YEUNG\\Anaconda3\\envs\\dlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "student_log_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('student_log')]\n",
    "training_label_path = os.path.join(data_dir, 'training_label.csv')\n",
    "validation_test_label = os.path.join(data_dir, 'validation_test_label.csv')\n",
    "\n",
    "dfs = []\n",
    "for path in student_log_paths:\n",
    "    temp = pd.read_csv(path)\n",
    "    dfs.append(temp)\n",
    "student_df = pd.concat(dfs)\n",
    "\n",
    "training_label_df = pd.read_csv(training_label_path)\n",
    "validation_test_label_df = pd.read_csv(validation_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_df.shape: (942816, 77)\n",
      "training_label_df.shape: (514, 5)\n",
      "validation_test_label_df.shape: (172, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"student_df.shape:\", student_df.shape) \n",
    "print(\"training_label_df.shape:\", training_label_df.shape)\n",
    "print(\"validation_test_label_df.shape:\", validation_test_label_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_specific_columns = [\"AveKnow\",\n",
    "                            \"AveCarelessness\",\n",
    "                            \"AveCorrect\",\n",
    "                            \"NumActions\",\n",
    "                            \"AveResBored\",\n",
    "                            \"AveResEngcon\",\n",
    "                            \"AveResConf\",\n",
    "                            \"AveResFrust\",\n",
    "                            \"AveResOfftask\",\n",
    "                            \"AveResGaming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_cols = ['ITEST_id'] + student_specific_columns\n",
    "student_specific_df = student_df[required_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEST_id</th>\n",
       "      <th>AveKnow</th>\n",
       "      <th>AveCarelessness</th>\n",
       "      <th>AveCorrect</th>\n",
       "      <th>NumActions</th>\n",
       "      <th>AveResBored</th>\n",
       "      <th>AveResEngcon</th>\n",
       "      <th>AveResConf</th>\n",
       "      <th>AveResFrust</th>\n",
       "      <th>AveResOfftask</th>\n",
       "      <th>AveResGaming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.352416</td>\n",
       "      <td>0.183276</td>\n",
       "      <td>0.483902</td>\n",
       "      <td>1056</td>\n",
       "      <td>0.208389</td>\n",
       "      <td>0.679126</td>\n",
       "      <td>0.115905</td>\n",
       "      <td>0.112408</td>\n",
       "      <td>0.156503</td>\n",
       "      <td>0.196561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>35</td>\n",
       "      <td>0.255164</td>\n",
       "      <td>0.158848</td>\n",
       "      <td>0.379658</td>\n",
       "      <td>993</td>\n",
       "      <td>0.222796</td>\n",
       "      <td>0.650079</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>0.164347</td>\n",
       "      <td>0.153147</td>\n",
       "      <td>0.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>39</td>\n",
       "      <td>0.281693</td>\n",
       "      <td>0.152227</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>418</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.628075</td>\n",
       "      <td>0.116390</td>\n",
       "      <td>0.143827</td>\n",
       "      <td>0.221926</td>\n",
       "      <td>0.019817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>64</td>\n",
       "      <td>0.157938</td>\n",
       "      <td>0.098357</td>\n",
       "      <td>0.334038</td>\n",
       "      <td>1419</td>\n",
       "      <td>0.198394</td>\n",
       "      <td>0.670062</td>\n",
       "      <td>0.085895</td>\n",
       "      <td>0.132328</td>\n",
       "      <td>0.115773</td>\n",
       "      <td>0.303426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>77</td>\n",
       "      <td>0.191948</td>\n",
       "      <td>0.094195</td>\n",
       "      <td>0.413249</td>\n",
       "      <td>317</td>\n",
       "      <td>0.261455</td>\n",
       "      <td>0.638636</td>\n",
       "      <td>0.063971</td>\n",
       "      <td>0.129858</td>\n",
       "      <td>0.234331</td>\n",
       "      <td>0.045096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ITEST_id   AveKnow  AveCarelessness  AveCorrect  NumActions  \\\n",
       "0            8  0.352416         0.183276    0.483902        1056   \n",
       "1056        35  0.255164         0.158848    0.379658         993   \n",
       "2049        39  0.281693         0.152227    0.454545         418   \n",
       "2467        64  0.157938         0.098357    0.334038        1419   \n",
       "3886        77  0.191948         0.094195    0.413249         317   \n",
       "\n",
       "      AveResBored  AveResEngcon  AveResConf  AveResFrust  AveResOfftask  \\\n",
       "0        0.208389      0.679126    0.115905     0.112408       0.156503   \n",
       "1056     0.222796      0.650079    0.069987     0.164347       0.153147   \n",
       "2049     0.274700      0.628075    0.116390     0.143827       0.221926   \n",
       "2467     0.198394      0.670062    0.085895     0.132328       0.115773   \n",
       "3886     0.261455      0.638636    0.063971     0.129858       0.234331   \n",
       "\n",
       "      AveResGaming  \n",
       "0         0.196561  \n",
       "1056      0.236800  \n",
       "2049      0.019817  \n",
       "2467      0.303426  \n",
       "3886      0.045096  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_specific_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=training_label_df, right=student_specific_df, how='left')\n",
    "X = combined_df[student_specific_columns].values\n",
    "y = combined_df['isSTEM'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=validation_test_label_df, right=student_specific_df, how='left')\n",
    "X_target = combined_df[student_specific_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: AUC: 0.62017, RMSE: 0.55470\n",
      "Test:  AUC: 0.96599, RMSE: 0.14712\n",
      "==============================\n",
      "Train: AUC: 0.61933, RMSE: 0.53709\n",
      "Test:  AUC: 0.94898, RMSE: 0.18019\n",
      "==============================\n",
      "Train: AUC: 0.63529, RMSE: 0.55470\n",
      "Test:  AUC: 0.94580, RMSE: 0.19182\n",
      "==============================\n",
      "Train: AUC: 0.75210, RMSE: 0.45993\n",
      "Test:  AUC: 0.95578, RMSE: 0.16775\n",
      "==============================\n",
      "Train: AUC: 0.72185, RMSE: 0.45993\n",
      "Test:  AUC: 0.94898, RMSE: 0.18019\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, mean_squared_error\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    \n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test set evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc_test = auc(fpr, tpr)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # train set evaluation\n",
    "    y_pred = model.predict(X_train)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_pred, pos_label=1)\n",
    "    auc_train = auc(fpr, tpr)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    print('Test: AUC: {:.5f}, RMSE: {:.5f}'.format(auc_test, rmse_test))\n",
    "    print('Train:  AUC: {:.5f}, RMSE: {:.5f}'.format(auc_train, rmse_train))\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X, y)\n",
    "y_target = model.predict_proba(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.61921,0.59038,0.32891,0.23993,0.63220,0.74379,0.34435,0.57852,0.58853,0.09773,0.19914,0.33141,0.11149,0.51188,0.62870,0.52403,0.48054,0.18729,0.45806,0.06627,0.81072,0.05268,0.80350,0.31453,0.18760,0.32789,0.11479,0.04370,0.17218,0.31965,0.35144,0.15714,0.07110,0.61839,0.16736,0.57225,0.27351,0.22354,0.25955,0.71901,0.27875,0.41441,0.08022,0.26384,0.26927,0.08260,0.12545,0.21938,0.55250,0.04789,0.52754,0.08911,0.49590,0.10723,0.19107,0.82243,0.17529,0.40207,0.26001,0.62066,0.16531,0.51456,0.39432,0.08400,0.53511,0.68250,0.24000,0.63259,0.75695,0.30456,0.44533,0.07078,0.74525,0.14375,0.66972,0.16094,0.08068,0.68565,0.28065,0.43642,0.73147,0.80384,0.10196,0.25253,0.21948,0.45372,0.23051,0.06396,0.20761,0.15556,0.38898,0.09758,0.68496,0.24765,0.47147,0.69151,0.30053,0.59636,0.24219,0.50756,0.69032,0.66535,0.19947,0.52824,0.47725,0.48708,0.47691,0.05420,0.95628,0.20905,0.23647,0.12839,0.32019,0.09295,0.84258,0.81318,0.15375,0.52271,0.21582,0.09825,0.07791,0.33452,0.51064,0.03593,0.29691,0.11187,0.57720,0.17844,0.23543,0.16200,0.08488,0.06943,0.20463,0.88830,0.06229,0.05303,0.52225,0.45169,0.36533,0.24906,0.21514,0.14659,0.24069,0.28188,0.49552,0.20430,0.39012,0.41134,0.24584,0.60468,0.05078,0.32084,0.78027,0.60260,0.27944,0.12193,0.37908,0.06014,0.40884,0.22017,0.07745,0.20802,0.14894,0.09762,0.06848,0.59636,0.23015,0.53820,0.09938,0.69926,0.40507,0.59754'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction submit result\n",
    "result = ','.join([\"{:.5f}\".format(i[1]) for i in y_target])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-c1d92737e2ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "def hyper_parameter_search(input_shape, num_classes):\n",
    "    num_hidden_layers = np.random.choice([3, 4], p=[0.5, 0.5])\n",
    "    reg_lambda = np.random.uniform(low=0.001, high=0.01)\n",
    "    hidden_layer_units = []\n",
    "    for i in range(num_hidden_layers):\n",
    "        # discrete uniform\n",
    "        units = np.random.randint(low=50, high=200)\n",
    "        hidden_layer_units.append(units)\n",
    "\n",
    "    print(\"num_hidden_layers:\", num_hidden_layers)\n",
    "    print(\"lambda\", reg_lambda)\n",
    "    print(\"hidden_layer_units\", hidden_layer_units)\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for units in hidden_layer_units:\n",
    "        model.add(Dense(units, input_dim=input_shape,\n",
    "                        kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                        activation='relu'))\n",
    "        input_shape = units\n",
    "\n",
    "    assert(num_classes == 1)\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
