{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "\n",
    "student_log_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('student_log')]\n",
    "training_label_path = os.path.join(data_dir, 'training_label.csv')\n",
    "validation_test_label = os.path.join(data_dir, 'validation_test_label.csv')\n",
    "\n",
    "dfs = []\n",
    "for path in student_log_paths:\n",
    "    temp = pd.read_csv(path)\n",
    "    dfs.append(temp)\n",
    "student_df = pd.concat(dfs)\n",
    "\n",
    "training_label_df = pd.read_csv(training_label_path)\n",
    "validation_test_label_df = pd.read_csv(validation_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"student_df.shape:\", student_df.shape) \n",
    "print(\"training_label_df.shape:\", training_label_df.shape)\n",
    "print(\"validation_test_label_df.shape:\", validation_test_label_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_specific_columns = [\"AveKnow\",\n",
    "                            \"AveCarelessness\",\n",
    "                            \"AveCorrect\",\n",
    "                            \"NumActions\",\n",
    "                            \"AveResBored\",\n",
    "                            \"AveResEngcon\",\n",
    "                            \"AveResConf\",\n",
    "                            \"AveResFrust\",\n",
    "                            \"AveResOfftask\",\n",
    "                            \"AveResGaming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_cols = ['ITEST_id'] + student_specific_columns\n",
    "student_specific_df = student_df[required_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "student_specific_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=training_label_df, right=student_specific_df, how='left')\n",
    "X = combined_df[student_specific_columns].values\n",
    "y = combined_df['isSTEM'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('assisstment_student_new_state.pkl', 'rb') as state_file:\n",
    "    dkt_df = pickle.load(state_file)\n",
    "student_specific_df = pd.merge(left=student_specific_df, right=dkt_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=validation_test_label_df, right=student_specific_df, how='left')\n",
    "X_target = combined_df[student_specific_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, mean_squared_error\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    \n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test set evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc_test = auc(fpr, tpr)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # train set evaluation\n",
    "    y_pred = model.predict(X_train)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_pred, pos_label=1)\n",
    "    auc_train = auc(fpr, tpr)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    print('Test: AUC: {:.5f}, RMSE: {:.5f}'.format(auc_test, rmse_test))\n",
    "    print('Train:  AUC: {:.5f}, RMSE: {:.5f}'.format(auc_train, rmse_train))\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X, y)\n",
    "y_target = model.predict_proba(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction submit result\n",
    "result = ','.join([\"{:.5f}\".format(i[1]) for i in y_target])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "def hyper_parameter_search(input_shape, num_classes):\n",
    "    num_hidden_layers = np.random.choice([3, 4], p=[0.5, 0.5])\n",
    "    reg_lambda = np.random.uniform(low=0.001, high=0.01)\n",
    "    hidden_layer_units = []\n",
    "    for i in range(num_hidden_layers):\n",
    "        # discrete uniform\n",
    "        units = np.random.randint(low=50, high=200)\n",
    "        hidden_layer_units.append(units)\n",
    "\n",
    "    print(\"num_hidden_layers:\", num_hidden_layers)\n",
    "    print(\"lambda\", reg_lambda)\n",
    "    print(\"hidden_layer_units\", hidden_layer_units)\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for units in hidden_layer_units:\n",
    "        model.add(Dense(units, input_dim=input_shape,\n",
    "                        kernel_regularizer=regularizers.l2(reg_lambda),\n",
    "                        activation='relu'))\n",
    "        input_shape = units\n",
    "\n",
    "    assert(num_classes == 1)\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
