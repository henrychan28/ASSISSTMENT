{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DKT Model for ASSISSTMENT </h1>\n",
    "<p> This notebook is for creating RNN model for generating output vector as a feature for predicting student's property </p>\n",
    "\n",
    "<i>\n",
    "DKT Model Code for this project is based on: https://github.com/davidoj/deepknowledgetracingTF\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Processing Block </h1>\n",
    "<p> Student logs, including training and validation set, are loaded into the notebook in pandas dataframe. After loading, useful columns are extracted and stored into the following:</p>\n",
    "<h3>Variables</h3>\n",
    "<ul>\n",
    "    <li> \n",
    "        <b>training_label_df, validation_test_label, student_df</b>: Includes all columns from the original file \n",
    "    </li>\n",
    "    <li>\n",
    "        <b>student_df_dkt</b>: Columns <i>\"ITEST_id\", \"skill\", \"actionId\" and \"correct\"</i> are extracted. All records with same ITEST_id are gathered togethered and sorted in ascending order with respect to actionId.\n",
    "    </li>\n",
    "    <li> \n",
    "        <b>skill_list</b>: All skills included in the student records are extracted. It <b>MUST</b> be used for onehot encoding later to maintain encoding consistency. <b><i>[!IMPORTANT]</i></b>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>id_entrynum</b>: A dictionary with ITESTId(Key), num entry(value), sorted by ITESTId\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<h3>Functions</h3>\n",
    "\n",
    "<b>student_dkt_data(data, skill_list=skill_list, id_entrynum=id_entrynum)</b>\n",
    "<ul>\n",
    "    <li> data: student_df_dkt in pandas dataframe sorted in ITEST_id and actionId </li>\n",
    "    <li> skill_list: The list stored all skills in a given order </li>\n",
    "    <li> id_entrynum: a dictionary sorted in ITESTId with value on num of entries per ITESTId </li>\n",
    "    <li> Output[i]: [# of questions answer of student i, (skills of questions, correctness of the answer)] </li>\n",
    "</ul>\n",
    "\n",
    "<i>Last update: 31/10/2017 </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "# Merge student logs into pandas data frame\n",
    "data_dir = './data/'\n",
    "\n",
    "student_log_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.startswith('student_log')]\n",
    "training_label_path = os.path.join(data_dir, 'training_label.csv')\n",
    "validation_test_label = os.path.join(data_dir, 'validation_test_label.csv')\n",
    "\n",
    "dfs = []\n",
    "for path in student_log_paths:\n",
    "    temp = pd.read_csv(path)\n",
    "    dfs.append(temp)\n",
    "student_df = pd.concat(dfs)\n",
    "\n",
    "training_label_df = pd.read_csv(training_label_path)\n",
    "validation_test_label_df = pd.read_csv(validation_test_label)\n",
    "student_df = student_df[student_df.scaffold == 0]\n",
    "\n",
    "student_df_dkt_static = student_df[['ITEST_id', 'AveKnow', 'AveCarelessness', 'AveCorrect', 'AveResBored', 'AveResEngcon', 'AveResConf' , 'AveResFrust', 'AveResOfftask', 'AveResGaming']]\n",
    "student_df_dkt_dynamic = student_df[['ITEST_id', 'skill', 'actionId', 'correct', 'hint', 'hintCount', 'hintTotal']]\n",
    "student_df_dkt_static = student_df_dkt_static.drop_duplicates()\n",
    "# Please do not modify this one. This will be the skill_list used throughout the whole training\n",
    "skill_list = student_df_dkt_dynamic.skill.unique()\n",
    "\n",
    "#Sort student_df according to ITESTId then actionId\n",
    "student_df_dkt_dynamic.sort_values([\"ITEST_id\",\"actionId\"], inplace=True, ascending=True)\n",
    "\n",
    "# Create a dictionary with ITESTId(Key), num entry(value), sorted by ITESTId\n",
    "id_entrynum = student_df_dkt_dynamic.groupby('ITEST_id').nunique()['actionId'].to_dict()\n",
    "id_entrynum = collections.OrderedDict(sorted(id_entrynum.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ITEST_id   AveKnow  AveCarelessness  AveCorrect  AveResBored  \\\n",
      "0             8  0.352416         0.183276    0.483902     0.208389   \n",
      "1056         35  0.255164         0.158848    0.379658     0.222796   \n",
      "2049         39  0.281693         0.152227    0.454545     0.274700   \n",
      "2467         64  0.157938         0.098357    0.334038     0.198394   \n",
      "3886         77  0.191948         0.094195    0.413249     0.261455   \n",
      "4203        126  0.250838         0.111159    0.500000     0.273188   \n",
      "4609        134  0.183801         0.113211    0.323420     0.267901   \n",
      "4878        156  0.271432         0.183643    0.384766     0.255130   \n",
      "5390        160  0.222439         0.146000    0.387009     0.234373   \n",
      "6129        164  0.117598         0.081440    0.256983     0.252204   \n",
      "6308        205  0.229988         0.126401    0.445407     0.242691   \n",
      "6885        215  0.313221         0.184542    0.475655     0.257214   \n",
      "7419        243  0.388355         0.218368    0.566243     0.251760   \n",
      "7970        255  0.150977         0.098634    0.277822     0.201959   \n",
      "9219        261  0.104958         0.058341    0.291274     0.213605   \n",
      "10812       283  0.146352         0.093224    0.309661     0.211405   \n",
      "12023       285  0.175748         0.110363    0.354637     0.260853   \n",
      "12821       291  0.109906         0.058950    0.275910     0.202929   \n",
      "13535       299  0.193344         0.124177    0.392449     0.221648   \n",
      "14409       337  0.397784         0.203061    0.463687     0.253448   \n",
      "15125       344  0.140497         0.070146    0.328160     0.212086   \n",
      "15576       349  0.280042         0.163547    0.432943     0.222461   \n",
      "16687       360  0.150901         0.089865    0.327911     0.221344   \n",
      "17855       372  0.139289         0.098821    0.333333     0.274414   \n",
      "18017       383  0.111148         0.069152    0.255167     0.201512   \n",
      "19275       391  0.116830         0.069112    0.291091     0.199464   \n",
      "20577       401  0.158852         0.102014    0.302120     0.220783   \n",
      "21143       404  0.442745         0.213176    0.560386     0.228357   \n",
      "21557       410  0.121571         0.079202    0.291793     0.236535   \n",
      "22215       418  0.127843         0.090719    0.254202     0.244744   \n",
      "...         ...       ...              ...         ...          ...   \n",
      "44640      7179  0.200418         0.104517    0.422131     0.268287   \n",
      "44884      7183  0.145442         0.071875    0.394595     0.254526   \n",
      "45254      7187  0.085334         0.051925    0.276018     0.240239   \n",
      "45696      7190  0.114802         0.071009    0.412698     0.246038   \n",
      "46074      7211  0.436720         0.193448    0.661538     0.234748   \n",
      "46334      7223  0.054794         0.045845    0.277228     0.247032   \n",
      "46637      7224  0.309172         0.156354    0.502793     0.259116   \n",
      "46995      7225  0.093756         0.061616    0.335570     0.296853   \n",
      "47293      7233  0.078163         0.071539    0.274510     0.267752   \n",
      "48007      7236  0.129049         0.071729    0.376518     0.289565   \n",
      "48254      7238  0.163380         0.065803    0.396825     0.329290   \n",
      "48317      7239  0.141000         0.076108    0.379845     0.270093   \n",
      "48833      7247  0.694489         0.404782    0.755920     0.236557   \n",
      "49382      7251  0.366283         0.220399    0.462396     0.257450   \n",
      "49741      7259  0.196931         0.123125    0.409449     0.276523   \n",
      "49995      7267  0.541876         0.281699    0.663265     0.238405   \n",
      "50485      7269  0.217077         0.075765    0.509259     0.343380   \n",
      "50593      7278  0.106437         0.042012    0.284171     0.180400   \n",
      "52444      7283  0.143799         0.083399    0.369352     0.232805   \n",
      "52953      7288  0.249765         0.089402    0.548077     0.285176   \n",
      "53057      7289  0.080731         0.049737    0.351648     0.306381   \n",
      "53421      7297  0.131786         0.088934    0.294521     0.307524   \n",
      "53567      7302  0.099464         0.067999    0.354839     0.290299   \n",
      "53691      7307  0.100750         0.064784    0.303704     0.219303   \n",
      "54366      7308  0.319437         0.169185    0.543568     0.266112   \n",
      "54607      7310  0.149338         0.088922    0.372188     0.272106   \n",
      "55096      7313  0.190340         0.085244    0.458101     0.236292   \n",
      "56349      7341  0.132166         0.088983    0.354271     0.253697   \n",
      "56747      7345  0.083869         0.047909    0.295229     0.202815   \n",
      "57753      7355  0.371038         0.181229    0.598891     0.230801   \n",
      "\n",
      "       AveResEngcon  AveResConf  AveResFrust  AveResOfftask  AveResGaming  \n",
      "0          0.679126    0.115905     0.112408       0.156503      0.196561  \n",
      "1056       0.650079    0.069987     0.164347       0.153147      0.236800  \n",
      "2049       0.628075    0.116390     0.143827       0.221926      0.019817  \n",
      "2467       0.670062    0.085895     0.132328       0.115773      0.303426  \n",
      "3886       0.638636    0.063971     0.129858       0.234331      0.045096  \n",
      "4203       0.646944    0.104602     0.131632       0.230005      0.040233  \n",
      "4609       0.612556    0.133687     0.088761       0.238335      0.062208  \n",
      "4878       0.637416    0.134121     0.110669       0.208373      0.052069  \n",
      "5390       0.647306    0.106632     0.100563       0.139646      0.096695  \n",
      "6129       0.597314    0.135032     0.105664       0.243513      0.214158  \n",
      "6308       0.658863    0.112356     0.132230       0.185330      0.077827  \n",
      "6885       0.655021    0.180377     0.107811       0.206081      0.031978  \n",
      "7419       0.676142    0.108132     0.086803       0.208193      0.024506  \n",
      "7970       0.676253    0.112641     0.096218       0.120190      0.345565  \n",
      "9219       0.686996    0.065391     0.130391       0.132007      0.399145  \n",
      "10812      0.655711    0.079308     0.102920       0.126860      0.245489  \n",
      "12023      0.637647    0.125193     0.127093       0.177880      0.056117  \n",
      "12821      0.676277    0.026768     0.099312       0.133908      0.387274  \n",
      "13535      0.654010    0.113191     0.210527       0.144921      0.186947  \n",
      "14409      0.652362    0.101359     0.124998       0.180844      0.098781  \n",
      "15125      0.656421    0.053397     0.084575       0.165763      0.374551  \n",
      "15576      0.672748    0.088712     0.212787       0.155201      0.078212  \n",
      "16687      0.658256    0.101942     0.112645       0.137649      0.173189  \n",
      "17855      0.598324    0.155372     0.188879       0.242912      0.089044  \n",
      "18017      0.669242    0.068417     0.133280       0.119863      0.351914  \n",
      "19275      0.664513    0.084895     0.133488       0.113943      0.344927  \n",
      "20577      0.644451    0.055901     0.161662       0.182277      0.264357  \n",
      "21143      0.673594    0.103765     0.150424       0.169761      0.047129  \n",
      "21557      0.635491    0.097208     0.107953       0.164068      0.180101  \n",
      "22215      0.631750    0.154620     0.153091       0.166027      0.106395  \n",
      "...             ...         ...          ...            ...           ...  \n",
      "44640      0.643537    0.108830     0.114511       0.258720      0.013371  \n",
      "44884      0.655368    0.106516     0.100395       0.209742      0.071460  \n",
      "45254      0.617677    0.094725     0.148926       0.183502      0.216114  \n",
      "45696      0.668582    0.245046     0.093585       0.196150      0.045616  \n",
      "46074      0.680063    0.106300     0.089435       0.210060      0.011170  \n",
      "46334      0.604602    0.102298     0.127687       0.214142      0.252059  \n",
      "46637      0.612901    0.134742     0.115463       0.202732      0.047601  \n",
      "46995      0.626489    0.118352     0.137352       0.266163      0.032202  \n",
      "47293      0.633112    0.156807     0.157443       0.156329      0.070266  \n",
      "48007      0.587557    0.125449     0.234331       0.288358      0.097875  \n",
      "48254      0.596042    0.140396     0.050503       0.465584      0.012057  \n",
      "48317      0.636907    0.127881     0.108874       0.192015      0.048788  \n",
      "48833      0.654716    0.043390     0.202432       0.209349      0.005129  \n",
      "49382      0.616064    0.080211     0.158224       0.199260      0.079190  \n",
      "49741      0.619168    0.183408     0.263782       0.241414      0.016554  \n",
      "49995      0.681001    0.085393     0.168892       0.183989      0.008419  \n",
      "50485      0.573485    0.095463     0.058775       0.381513      0.005970  \n",
      "50593      0.694537    0.027727     0.135643       0.088539      0.652089  \n",
      "52444      0.655073    0.097681     0.137310       0.186073      0.276959  \n",
      "52953      0.624537    0.130070     0.039878       0.343589      0.005644  \n",
      "53057      0.632865    0.131581     0.191030       0.285214      0.023231  \n",
      "53421      0.629944    0.168628     0.046866       0.349393      0.046889  \n",
      "53567      0.640328    0.082238     0.277903       0.343747      0.095764  \n",
      "53691      0.673833    0.123298     0.082113       0.151845      0.284216  \n",
      "54366      0.653284    0.140156     0.095810       0.210960      0.015541  \n",
      "54607      0.652156    0.140214     0.101179       0.196539      0.032502  \n",
      "55096      0.621885    0.095735     0.177521       0.159310      0.063946  \n",
      "56349      0.655202    0.135009     0.116272       0.189618      0.110394  \n",
      "56747      0.673231    0.099097     0.104775       0.129066      0.449026  \n",
      "57753      0.698270    0.074955     0.118799       0.161527      0.054416  \n",
      "\n",
      "[1709 rows x 10 columns]\n",
      "{0: 'properties-of-geometric-figures', 1: 'sum-of-interior-angles-more-than-3-sides', 2: 'point-plotting', 3: 'reading-graph', 4: 'area', 5: 'square-root', 6: 'isosceles-triangle', 7: 'application: isosceles triangle', 8: 'multiplying-decimals', 9: 'interpreting-linear-equations', 10: 'pattern-finding', 11: 'proportion', 12: 'application: compare points', 13: 'application: multi-column subtraction', 14: 'application: simple multiplication', 15: 'application: compare expressions', 16: 'application: order of operations', 17: 'application: multi-column addition', 18: 'noskill', 19: 'application: read points', 20: 'application: find slope in graph', 21: 'p-patterns-relations-algebra', 22: 'pythagorean-theorem', 23: 'percent-of', 24: 'equivalent-fractions-decimals-percents', 25: 'fraction-multiplication', 26: 'supplementary-angles', 27: 'triangle-inequality', 28: 'multiplication', 29: 'equation-solving', 30: 'discount', 31: 'sum-of-interior-angles-triangle', 32: 'inducing-functions', 33: 'subtraction', 34: 'addition', 35: 'division', 36: 'divide-decimals', 37: 'making-sense-of-expressions-and-equations', 38: 'ordering-numbers', 39: 'fraction-division', 40: 'evaluating-functions', 41: 'substitution', 42: 'algebraic-manipulation', 43: 'number-line', 44: 'exponents', 45: 'comparing-fractions', 46: 'scientific-notation', 47: 'order-of-operations', 48: 'reciprocal', 49: 'finding-percents', 50: 'subtracting-decimals', 51: 'integers', 52: 'probability', 53: 'combinatorics', 54: 'symbolization-articulation', 55: 'mean', 56: 'meaning-of-pi', 57: 'interpreting-numberline', 58: 'graph-shape', 59: 'linear-area-volume-conversion', 60: 'inequality-solving', 61: 'fractions', 62: 'percents', 63: 'unit-conversion', 64: 'equation-concept', 65: 'rate', 66: 'median', 67: 'mode', 68: 'statistics', 69: 'circle-graph', 70: 'n-number-sense-operations', 71: 'perimeter', 72: 'venn-diagram', 73: 'transversals', 74: 'congruence', 75: 'of-means-multiply', 76: 'transformations-rotations', 77: 'least-common-multiple', 78: 'fraction-decimals-percents', 79: 'inequalities', 80: 'graph interpretation', 81: 'algebra symbolization', 82: 'surface-area-and-volume', 83: 'prime-number', 84: 'rounding', 85: 'stem-and-leaf-plot', 86: 'multiplying-positive-negative-numbers', 87: 'circumference', 88: 'application: finding percentage of a number', 89: 'area-of-circle', 90: 'm-measurement', 91: 'rate-with-distance-and-time', 92: 'area-concept', 93: 'reduce-fraction', 94: 'divisibility', 95: 'properties-of-solids', 96: 'adding-decimals', 97: 'simple-calculation', 98: 'measurement', 99: 'g-geometry', 100: 'similar-triangles', 101: 'slope'}\n"
     ]
    }
   ],
   "source": [
    "print(student_df_dkt_static)\n",
    "skill_list_index= dict(zip(range(len(skill_list)),skill_list))\n",
    "print(skill_list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def student_dkt_data(data, skill_list=skill_list, id_entrynum=id_entrynum):\n",
    "    # Input:\n",
    "    # data - student_df_dkt in pandas dataframe sorted in ITEST_id and actionId\n",
    "    # skill_list - the list stored all skills in a give order\n",
    "    # id_entrynum - a dictionary sorted in ITESTId with value on num of entries per ITESTId\n",
    "    # Output - Output[i] = [# of questions answer of student i, skills of questions, correctness of the answer]\n",
    "    v = []\n",
    "    # temporary function for converting skill into a number representing that skills (need to do oneshot later)\n",
    "    f = lambda x: np.where(skill_list == x)[0][0] \n",
    "    for key, value in id_entrynum.items():\n",
    "        skill = list(map(f, data[data['ITEST_id'] == key]['skill'].values))\n",
    "        correct = data[data['ITEST_id'] == key]['correct'].values.tolist()\n",
    "        v.append((key, np.asscalar(value), list(zip(skill, correct))))\n",
    "    return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assisstment_dynamic.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b8d1c65aa91f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"assisstment_dynamic.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Unpickling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"assisstment_static.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# Unpickling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assisstment_dynamic.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"assisstment_dynamic.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "with open(\"assisstment_static.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    c = pickle.load(fp)\n",
    "with open(\"assisstment_skill.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    d = pickle.load(fp)\n",
    "    \n",
    "print(b[['ITEST_id', 'correct', 'skill']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8\n",
       "1       8\n",
       "2       8\n",
       "3       8\n",
       "4       8\n",
       "5       8\n",
       "6       8\n",
       "7       8\n",
       "8       8\n",
       "9       8\n",
       "10      8\n",
       "11      8\n",
       "12      8\n",
       "13      8\n",
       "14      8\n",
       "15      8\n",
       "16      8\n",
       "17      8\n",
       "18      8\n",
       "19      8\n",
       "20      8\n",
       "21      8\n",
       "22      8\n",
       "23      8\n",
       "24      8\n",
       "25      8\n",
       "26      8\n",
       "27      8\n",
       "28      8\n",
       "29      8\n",
       "       ..\n",
       "1026    8\n",
       "1027    8\n",
       "1028    8\n",
       "1029    8\n",
       "1030    8\n",
       "1031    8\n",
       "1032    8\n",
       "1033    8\n",
       "1034    8\n",
       "1035    8\n",
       "1036    8\n",
       "1037    8\n",
       "1038    8\n",
       "1039    8\n",
       "1040    8\n",
       "1041    8\n",
       "1042    8\n",
       "1043    8\n",
       "1044    8\n",
       "1045    8\n",
       "1046    8\n",
       "1047    8\n",
       "1048    8\n",
       "1049    8\n",
       "1050    8\n",
       "1051    8\n",
       "1052    8\n",
       "1053    8\n",
       "1054    8\n",
       "1055    8\n",
       "Name: ITEST_id, Length: 1056, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df_dkt[student_df_dkt['ITEST_id'] == 8]['ITEST_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model Definition </h1>\n",
    "<p> Here are parameters of the model: </p>\n",
    "<ul>\n",
    "    <li><b>batch_size</b>: minibatch size</li>\n",
    "    <li><b>num_probs</b>: number of unique problems in the dataset</li>\n",
    "    <li><b>embedding_size</b>: size of the embedding lookup layer</li>\n",
    "    <li><b>num_hid</b>: number of units in the single hidden layer</li>\n",
    "    <li><b>initial_learning_rate</b>: learning rate of ADAM optmizer at first step of training</li>\n",
    "    <li><b>epsilon</b>: epsilon parameter of ADAM optimizer</li>\n",
    "    <li><b>final_learning_rate</b>: learning rate after 3000 training steps (linear decay)</li>\n",
    "    <li><b>keep_prob</b>: keep probability for dropout layer</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(   \n",
    "            self,\n",
    "            batch_size,\n",
    "            num_probs,\n",
    "            embedding_size=250,\n",
    "            num_hid=250,\n",
    "            initial_learning_rate=0.001,\n",
    "            final_learning_rate=0.001,\n",
    "            keep_prob=1,\n",
    "            epsilon=0.00001):\n",
    "        \"\"\"Create an LSTM for test score prediction\n",
    "        Args:\n",
    "            batch_size: minibatch size\n",
    "            num_probs: number of unique problems in the dataset\n",
    "            embedding_size: size of the embedding lookup layer\n",
    "            num_hid: number of units in the single hidden layer\n",
    "            initial_learning_rate: learning rate of ADAM optmizer at first step of training\n",
    "            epsilon: epsilon parameter of ADAM optimizer\n",
    "            final_learning_rate: learning rate after 3000 training steps (linear decay)\n",
    "            keep_prob: keep probability for dropout layer\n",
    "        Returns:\n",
    "            tuple: (optimizer, training_loss, validation_prediction)\n",
    "        \"\"\"\n",
    "\n",
    "        # Inputs\n",
    "        Xs = self._Xs = tf.placeholder(tf.int32, shape=[batch_size, None])\n",
    "        Ys = self._Ys = tf.placeholder(tf.float32, shape=[batch_size, None, num_probs])\n",
    "        targets = self._targets = tf.placeholder(tf.float32, shape=[batch_size, None])\n",
    "        sequence_length = self._seqlen = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "\n",
    "        # Global parameters\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.polynomial_decay(initial_learning_rate, global_step,5000,final_learning_rate)\n",
    "\n",
    "        # LSTM parameters\n",
    "        w = tf.Variable(tf.truncated_normal([num_hid, num_probs],stddev=1.0/np.sqrt(num_probs)))\n",
    "        b = tf.Variable(tf.truncated_normal([num_probs],stddev=1.0/np.sqrt(num_probs)))\n",
    "        embeddings = tf.Variable(tf.random_uniform([2*num_probs+2, embedding_size], -1.0, 1.0))\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(num_hid)\n",
    "        initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "\n",
    "        # LSTM Training ops\n",
    "        inputsX = tf.nn.embedding_lookup(embeddings,Xs)\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,inputsX,sequence_length,initial_state=initial_state)\n",
    "        if keep_prob != 1:\n",
    "            outputs = tf.nn.dropout(outputs, keep_prob)\n",
    "        outputs_flat = tf.reshape(outputs,shape=[-1,num_hid])\n",
    "        logits = tf.reshape(tf.nn.xw_plus_b(outputs_flat, w, b),shape=[batch_size,-1,num_probs])\n",
    "        self._pred_run = pred = tf.reduce_max(logits * Ys, axis=2)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=targets)\n",
    "        mask = tf.sign(tf.abs(pred))\n",
    "        loss_masked = mask*loss\n",
    "        loss_masked_by_s = tf.reduce_sum(loss_masked, axis=1)\n",
    "        mean_loss = self._loss = tf.reduce_mean(loss_masked_by_s/tf.to_float(sequence_length))\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = self._train = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "            epsilon=epsilon).minimize(mean_loss,global_step=global_step)\n",
    "        \n",
    "        saver = self._saver = tf.train.Saver()\n",
    "\n",
    "        # LSTM Validation ops\n",
    "        test_outputs, test_state = tf.nn.dynamic_rnn(cell,inputsX,sequence_length,initial_state)\n",
    "        test_outputs_flat = tf.reshape(test_outputs, shape=[-1,num_hid])\n",
    "        test_logits = tf.reshape(tf.nn.xw_plus_b(test_outputs_flat,w,b),shape=[batch_size,-1,num_probs])\n",
    "        test_pred = self._pred = tf.sigmoid(tf.reduce_sum(test_logits*Ys, axis=2))\n",
    "    \n",
    "    @property\n",
    "    def Xs(self):\n",
    "        return self._Xs\n",
    "\n",
    "    @property\n",
    "    def Ys(self):\n",
    "        return self._Ys\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self._targets\n",
    "\n",
    "    @property\n",
    "    def seq_len(self):\n",
    "        return self._seqlen\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self._loss\n",
    "\n",
    "    @property\n",
    "    def train_op(self):\n",
    "        return self._train\n",
    "\n",
    "    @property\n",
    "    def predict(self):\n",
    "        return self._pred\n",
    "    \n",
    "    @property\n",
    "    def predict_run(self):\n",
    "        return self._pred_run\n",
    "    \n",
    "    @property\n",
    "    def saver(self):\n",
    "        return self._saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Batch Generation</h1>\n",
    "<p>The following functions blocks are used for batch generation.</p>\n",
    "<h3>skill_onehot(skill, skill_length)</h3>\n",
    "<ul>\n",
    "    <li>\n",
    "        <b>skill</b>: the single type of skill wanted to be encoded, the number representing the skill is generated with respect to skill_list.\n",
    "    </li>\n",
    "     <li>\n",
    "         <b>skill_length</b>: the number of skill present in the dataset with respect to skill_list\n",
    "     </li>\n",
    "</ul>\n",
    "<h3>BatchGenerator <i>(class)</i></h3>\n",
    "<ul>\n",
    "    <h3>__init__(self,data,batch_size,skill_list,max_len)</h3>\n",
    "    \n",
    "     <li><b>data</b>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skill_onehot(skill, skill_length):\n",
    "    # skill - the single type of skill wanted to be encoded\n",
    "    # skill_length - the total number of skills in the problem space\n",
    "    # return - an onehot vector of the input skill with size skill_length \n",
    "    v = np.zeros((skill_length,))\n",
    "    v[skill] = 1\n",
    "    return v\n",
    "\n",
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self,data,batch_size,skill_list,max_len=3500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: score data in the format [[sequence_length, [(problem_id, success_or_fail)]]]\n",
    "                    each sequence is a different test taker\n",
    "                    list of test scores is in temporal order\n",
    "            batch_size: minibatch size to serve\n",
    "            max_len: the longest sequence of responses to keep\n",
    "        \"\"\"\n",
    "        self.data = sorted(data, key = lambda x: len(x[1]))\n",
    "        self.cursor = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.num_probs = len(skill_list)\n",
    "        self.n = len(data)\n",
    "            \n",
    "    def next_batch(self):\n",
    "        tups = []\n",
    "        n_samps = []\n",
    "        for i in range(self.batch_size):\n",
    "            tups.append(self.data[self.cursor][1][:self.max_len])            \n",
    "            n_samps.append(len(tups[-1]))\n",
    "            self.cursor = (self.cursor + 1) % len(self.data)\n",
    "        #print(\"tups:\", tups)\n",
    "        mlen = max(n_samps)\n",
    "        Xs = np.zeros((self.batch_size, mlen),dtype=np.int32)\n",
    "        Ys = np.zeros((self.batch_size, mlen, self.num_probs),dtype=np.int32)\n",
    "        targets = np.zeros((self.batch_size, mlen),dtype=np.int32)\n",
    "        for i, tuplist in enumerate(tups):\n",
    "            Xs[i] = np.pad([2 + t[0] + t[1]*self.num_probs for t in tuplist[:-1]],\n",
    "                (1,mlen-len(tuplist)),'constant',constant_values=(1,0))\n",
    "            Ys[i] = np.pad([skill_onehot(t[0],self.num_probs) for t in tuplist],\n",
    "                ((0,mlen-len(tuplist)),(0,0)),'constant',constant_values=0)\n",
    "            #print([t[0] for t in tuplist])\n",
    "            #print(\"hi\")\n",
    "            targets[i] = np.pad([t[1] for t in tuplist],(0,mlen-len(tuplist)),'constant',constant_values=0)\n",
    "        if self.cursor == 0: \n",
    "            pass\n",
    "            #print(\"Xs: \", Xs)\n",
    "        return Xs, Ys, targets, n_samps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Playground\n",
    "#train_batches = BatchGenerator(train_data,1, skill_list)\n",
    "#Xs, Ys, targets, n_samps = train_batches.next_batch()\n",
    "#print(Ys)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(session, train_batchgen, test_batchgen, train_steps):\n",
    "\n",
    "    m = Model(train_batchgen.batch_size,train_batchgen.num_probs)\n",
    "    with session.as_default() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        average_loss = 0\n",
    "        for step in range(train_steps):\n",
    "            batch_Xs, batch_Ys, batch_labels, batch_sequence_lengths = train_batches.next_batch()\n",
    "            feed_dict = {m.Xs : batch_Xs, m.Ys : batch_Ys, \n",
    "                         m.seq_len : batch_sequence_lengths, m.targets : batch_labels}\n",
    "            _, l, pred = session.run([m.train_op,m.loss, m.predict_run], feed_dict=feed_dict)\n",
    "            #print(pred)\n",
    "            average_loss += l\n",
    "            if step % 5 == 0:\n",
    "                average_loss = average_loss / min(100,step+1)\n",
    "                print('Average loss at step %d: %f' % (step, average_loss))\n",
    "                average_loss = 0\n",
    "            if step % 5 == 0:\n",
    "                auc = 0\n",
    "                for i in range(test_batchgen.n//train_batchgen.batch_size):\n",
    "                    test_batch_Xs, test_batch_Ys, test_batch_labels, test_batch_sequence_lengths = test_batchgen.next_batch()\n",
    "                    test_feed_dict = {m.Xs : test_batch_Xs, m.Ys : test_batch_Ys, \n",
    "                                      m.seq_len : test_batch_sequence_lengths}\n",
    "                    pred = session.run([m.predict], feed_dict=test_feed_dict)\n",
    "                    if step == 50:\n",
    "                        pass\n",
    "                        #print(pred)\n",
    "                    #print(pred)\n",
    "                    auc += roc_auc_score(test_batch_labels.reshape(-1),np.array(pred).reshape(-1))/(test_batchgen.n//train_batchgen.batch_size)\n",
    "                print(\"AUC Score: \", auc)\n",
    "                save_path = m.saver.save(session, './model.ckpt')\n",
    "                print('Model saved in {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Run Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process the data from student_df by student_dkt_data\n",
    "data = student_dkt_data(student_df_dkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJHUZFJKkLoNCktRlUEiSuv4vKw11SuxYnA8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28ab11dfb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "v0 = 0\n",
    "v1 = []\n",
    "for key, value in id_entrynum.items():\n",
    "    v1.append(value)\n",
    "plt.hist(v1, 500, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Training Data and Test Data Preparation #\n",
    "###########################################\n",
    "TRAINING_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.2\n",
    "train_data = data[:int(len(data)*TRAINING_RATIO)]\n",
    "test_data = data[int(len(data)*TRAINING_RATIO):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# Hyperparameter Setting #\n",
    "##########################\n",
    "BATCH_SIZE = 100\n",
    "TRAIN_STEPS = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 0.301429\n",
      "AUC Score:  0.583921725905\n",
      "Model saved in ./model.ckpt\n",
      "Average loss at step 5: 0.136764\n",
      "AUC Score:  0.574665880078\n",
      "Model saved in ./model.ckpt\n",
      "Average loss at step 10: 0.061589\n",
      "AUC Score:  0.580600620694\n",
      "Model saved in ./model.ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-cd738ecff976>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_STEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-0c9e5782e6c7>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(session, train_batchgen, test_batchgen, train_steps)\u001b[0m\n\u001b[0;32m     10\u001b[0m             feed_dict = {m.Xs : batch_Xs, m.Ys : batch_Ys, \n\u001b[0;32m     11\u001b[0m                          m.seq_len : batch_sequence_lengths, m.targets : batch_labels}\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_run\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;31m#print(pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0maverage_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############\n",
    "# RUN MODEL #\n",
    "#############\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_batches = BatchGenerator(train_data,BATCH_SIZE, skill_list)\n",
    "test_batches = BatchGenerator(test_data,BATCH_SIZE, skill_list)\n",
    "\n",
    "s = tf.Session()\n",
    "\n",
    "run(s, train_batches, test_batches, TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
